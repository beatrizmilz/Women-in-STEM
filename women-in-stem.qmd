---
title: "Revisiting the Women In STEM dataset"
subtitle: "Practical Implications of Using Inverse Transformations in Multiple Linear Regression"
author: "Lydia Gibson"
format: 
  revealjs:
    theme: serif
    footer: https://lgibson7.quarto.pub/women-in-stem/
---


# Introduction


```{r echo=FALSE, warning=FALSE, message=FALSE}
dat1 <- read.csv("women-stem.csv")

library(pacman)

suppressWarnings(p_load(dplyr, ggplot2, ggpubr, scales, MASS, car, lmtest, 
                        ggrepel, faraway, ggcorrplot, GGally, lindia, see, performance, qqplotr, ggstatsplot, rstantools, PMCMRplus))

options(scipen = 100) # remove scientific notation
```


---

In our previous research, *[Gender Wage Inequality in STEM](https://github.com/lgibson7/Gender-Wage-Inequality-in-STEM)*, my colleagues and I explored the the relationship between gender demographics and median salary of major categories within STEM for our STAT 632 Linear and Logistic Regression final project. ...... We fit a multiple linear regression model to explore the relationship between gender demographics and median salary of major categories within STEM, using the inverse transformation of median salary as the response variable to improve the fit of the regression model, then ran model diagnostics. 


# Data Source
  
The [Women In Stem](https://github.com/fivethirtyeight/data/blob/master/college-majors/women-stem.csv) data set used for the FiveThirtyEight article ["The Economic Guide To Picking A College Major"](https://fivethirtyeight.com/features/the-economic-guide-to-picking-a-college-major/), obtained from the American Community Survey (ACS) 2010-2012 Public Use Microdata Series (PUMS). It has 76 observations, each representing a STEM Major, and 9 variables: Rank, Major_code, Major,	Major_category,	Total,	Men,	Women,	ShareWomen, Median. For our analysis and regression modelling, we did not use Rank, Major_code, or Major, so that we could just focus on the five major categories: Engineering,	Physical Sciences, Computers & Mathematics, Health, and Biology & Life Science.


```{r echo=FALSE, warning=FALSE, message=FALSE}

# remove Rank, Major_code, and Major
dat2 <- dat1[,-c(1,2)] 

# Get totals for men and women for each major category
#dat_stats <- rbind(
  
  # Get totals for men
  #dat2 %>% group_by(Major_category) %>%
   # summarize(Grand_Total = sum(Men), Proportion=Grand_Total/sum(Total)) %>%
    #mutate(Sex="Men", labelpos=Proportion/2),
  
# Get totals for women
#dat2 %>% group_by(Major_category) %>%
 # summarize(Grand_Total = sum(Women), Proportion=Grand_Total/sum(Total)) %>%
 # mutate(Sex="Women", labelpos=1 - (Proportion/2))) %>% 
#  mutate(Sex = Sex %>% factor(levels=c("Women","Men")))

# Plot the gender proportions by major category
#dat_stats %>% ggplot(aes(x=Major_category,y=Proportion,fill=Sex)) +
  # stack side by side bars
 # stat_summary(geom = "bar", position="fill") +
  # get % labels
 # geom_text(aes(label = paste0(round(100*Proportion,2),"%"), 
 #               y=labelpos),size = 3,) +
  #scale_y_continuous(labels = scales::percent_format()) + 
 # labs(x="Major Category", y="Proportion of Gender (%)") +
 # scale_x_discrete(labels = scales::label_wrap(15)) +
  #scale_fill_manual(values = c("#fcdde5", "#73d1f9"))

head(dat2)
```

# Problem

While transforming response and explanatory variables is common in statistics, it often leads to models that are not easily explained to the average person. In this presentation, I will revisit the model that we fit and compare it with easier to explain models.

# Method

In our previous research, we took the following steps in exploratory data analysis:
- Used a bar chart to compare gender proportions per major category
- Used a boxplot to compare median wages of STEM major categories
- Ran an ANOVA to test whether the differences in median wage per STEM major category were statistically significant
- Used a jitter plot to analyze the proportion of women in the individual majors with each STEM major category
- Created a scatter plot matrix and correlation heat map to view the correlation between our response variable, Median, and the explanatory variables we selected

---
In our previous research, we took the following steps in modelling:
- Checked the normality assumption for our response variable, Median, using a histogram and box cox analysis
- Built our predictive models, with and without interactions, and tested the significance of our explantory variables to get a final reduced model
- Ran model diagnostics to test the residuals vs fitted values, a normal qq plot to test that the residuals are normally distributed, VIF for multicollinearity .......

---

Following all this, we ran predictive intervals for select Majors of each major category to see the effectiveness of our model.

In this project, I will redo many of these same analyses using both the untransformed and inverse of our response variable Median.

# Results

---

```{r echo=FALSE, message=FALSE, warning=FALSE}
  
# Get the outliers
outlier_pts <- dat1 %>%filter(Median > 100000 & Major_category == "Engineering" | (Median > 60000 & Major_category == "Physical Sciences"))

# Get a box plot for Major category by Median
bx_plt <- dat2 %>% ggplot(aes(x=Major_category,y=Median)) + 
  geom_boxplot(show.legend=FALSE) +
    labs(x="Major Category", y="Median Salary ($ 1000)") + 
  theme(axis.text.x=element_text(angle=0)) + 
  # label outliers
  geom_text(data=outlier_pts, aes(label=Major),nudge_y=2, vjust=-1.6, hjust=0.7, color = "Black", size= 2) + 
  # change scale labels of Median
  scale_y_continuous(breaks=c(40000,60000,80000,100000), 
                     labels=c("40","60","80","100")) +
     # Wrap text for major categories
  scale_x_discrete(labels = scales::label_wrap(15))

bx_plt

```


---

```{r}
ggbetweenstats(
  data  = dat2,
  x     = Major_category,
  y     = Median,
  title = "Distribution of Median Salaries across STEM Major Categories"
)
```


---

```{r}


# Box plots with jittered points
# :::::::::::::::::::::::::::::::::::::::::::::::::::
# Change outline colors by groups: dose
# Use custom color palette
# Add jitter points and change the shape by groups
 p <- ggboxplot(dat2, x = "Major_category", y = "Median",
                color = "Major_category", 
                add = "jitter")
 #p
 
  
 # Add p-values comparing groups
 # Specify the comparisons you want
my_comparisons <- list( c("Engineering", "Physical Sciences"), c("Computers & Mathematics", "Physical Sciences"), c("Health", "Biology & Life Science") )
p + stat_compare_means(comparisons = my_comparisons)+ # Add pairwise comparisons p-value
  stat_compare_means(label.y = 50)                   # Add global p-value
```


---

```{r echo=FALSE, message=FALSE, warning=FALSE}

# Get the outliers
outlier_pts <- dat1 %>%filter(Median > 100000 |(Median > 60000 & Major_category == "Physical Sciences"))

jitter_plt <- dat1 %>%ggplot(aes(x=Major_category,y=Median, color=Major_category, size=ShareWomen)) +
  geom_jitter(alpha = 1/2) +# make circle transparent to show overlap
  theme(axis.text.x = element_text(angle=0, vjust=0.65),
        plot.subtitle = element_text(hjust=0.5),
        legend.position = "right") +
  geom_text(data=outlier_pts, aes(label=Major, size=0.11),nudge_y=2, vjust=-1.6, hjust=0.7, color = "black") + # label outliers
  
   labs(x="Major Category", y="Median Salary ($ 1000)") +
guides(color = F, # remove legend for color
         size = guide_legend( # change size legend
           override.aes = list(alpha = 1))) +
  # Wrap text for major categories
  scale_x_discrete(labels = scales::label_wrap(15)) +
  scale_size_binned(breaks = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0)) +
   # change scale labels of Median
  scale_y_continuous(breaks=c(40000,60000,80000,100000),
                     labels=c("40","60","80","100")) 

jitter_plt + scale_colour_viridis_d(option = "B")

```

---

```{r echo=FALSE, warning=FALSE, message=FALSE}
ggpairs(dat2[,c(6,1:5)], c(1,3:6))


```

---

# Method


```{r echo=FALSE, warning=FALSE, message=FALSE}
lm_full <- lm(Median~.,data=dat2)
boxcox(lm_full, lambda=seq(-2.5, 0.5, by =0.5))
#summary(lm_full)$adj.r.squared
```


---

```{r}
hist(dat2$Median, breaks = 50)
```


----

```{r}
#plot(lm_full)
```



-----

```{r}
#gg_diagnose(lm_full)
#gg_qqplot(lm_full)
gg_boxcox(lm_full)
gghistogram(dat2$Median)

check <- check_normality(lm_full)
plot(check, type = "qq")
```


----




```{r echo=FALSE, warning=FALSE, message=FALSE}
library(performance)
library(see)


options(scipen=3)

lm_reduced <- lm((Median^(-1)) ~ Major_category + Men + ShareWomen + Men*ShareWomen,
                 data=dat2)

#gg_diagnose(lm_reduced)
#gg_qqplot(lm_reduced)
gg_boxcox(lm_reduced)
gghistogram(dat2$Median^-1)

check <- check_normality(lm_reduced)

plot(check, type = "qq")
```

# Results




```{r echo=FALSE, eval=F}
new_x<-data.frame(Major_category="Engineering", Men=2057, ShareWomen=0.12056434, Total=2339, Women=282

)
Median_Pet<-predict(lm_full, newdata = new_x, type = "response", interval = "prediction")

Median_Pet
```

```{r echo=FALSE, eval=F}
new_x<-data.frame(Major_category="Engineering", Men=2057, ShareWomen=0.12056434)
Median_Pet<-predict(lm_reduced, newdata = new_x, type = "response", interval = "prediction")

Median_Pet^-1
```


# Conclusion

- Inverse transformation creates non-symmetric confidence interval

- Inverse creates small predictions

# Further Research

- I would like to export data from ACS API to get more recent data and rerun the linear regression model using the [TidyModels](https://github.com/tidymodels) framework.

- I would like to compare and contrast the statistical data visualizations and calculations, such as boxplots, box cox, correlation heatmaps, scatterplot matrices, etc., from the various ggplot2 extensions used in this presentation (see, ggpubr, ggstatplot, lindia,ggcorrplot, ), to the statistical data visualizations available in base R.

# Code Appendix


